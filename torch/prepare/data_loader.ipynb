{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "928531fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from db.session import get_last_data_by_symbol\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import tracemalloc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f3adf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 1946\n"
     ]
    }
   ],
   "source": [
    "recordsAll = get_last_data_by_symbol(symbol=\"xar\", until=\"2025-06-26 00:00:00\")\n",
    "\n",
    "# Convert result to Pandas DataFrame\n",
    "df = pd.DataFrame(recordsAll.fetchall(), columns=list(recordsAll.keys()))\n",
    "# print count of rows\n",
    "print(f\"Total records: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb482b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of lastPrice: -0.3037851097481479\n",
      "Kurtosis of lastPrice: -1.4517396552829014\n",
      "Minimum of lastPrice: 0.002351\n",
      "Maximum of lastPrice: 0.005917\n",
      "Percentage Difference from Minimum: 151.68013611229267%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the timestamp column as the index\n",
    "df.set_index('created_at', inplace=True)\n",
    "\n",
    "df[\"price_change\"] = df[\"lastPrice\"].pct_change()\n",
    "df[\"volume_change\"] = df[\"volume24h\"].pct_change()\n",
    "df[\"bid_ask_ratio\"] = (df[\"bid1Size\"] / (df[\"ask1Size\"] + 1e-9))\n",
    "\n",
    "df[\"mean_price_2\"] = df[\"price_change\"].rolling(window=2).mean()\n",
    "df[\"mean_price_4\"] = df[\"price_change\"].rolling(window=4).mean()\n",
    "#df[\"mean_price_8\"] = df[\"price_change\"].rolling(window=8).mean()\n",
    "\n",
    "df[\"mean_volume_2\"] = df[\"volume_change\"].rolling(window=2).mean()\n",
    "df[\"mean_volume_4\"] = df[\"volume_change\"].rolling(window=4).mean()\n",
    "#df[\"mean_volume_8\"] = df[\"volume_change\"].rolling(window=8).mean()\n",
    "df[\"mean_volume_8_16\"] = df[\"volume_change\"].shift(8).rolling(window=8).mean()\n",
    "\n",
    "df[\"mean_bid_ask_ratio_4\"] = df[\"bid_ask_ratio\"].rolling(window=4).mean()\n",
    "df[\"mean_bid_ask_ratio_8_16\"] = df[\"bid_ask_ratio\"].shift(8).rolling(window=8).mean()\n",
    "\n",
    "# Target\n",
    "lp_shift_3 = df[\"lastPrice\"].shift(-3).rolling(window=3).mean()\n",
    "lp_shift_3_6 = df[\"lastPrice\"].shift(-6).rolling(window=3).mean()\n",
    "\n",
    "df[\"future_return_pcnt_3\"] = (lp_shift_3 - df[\"lastPrice\"]) / df[\"lastPrice\"] * 100\n",
    "df[\"future_return_pcnt_6\"] = (lp_shift_3_6 - df[\"lastPrice\"]) / df[\"lastPrice\"] * 100\n",
    "\n",
    "\n",
    "df[\"target_lp_sh_3\"] = (df[\"future_return_pcnt_3\"] >= 2).astype(int)\n",
    "df[\"target_lp_sh_6\"] = (df[\"future_return_pcnt_6\"] >= 5).astype(int)\n",
    "\n",
    "# Final target combining both conditions\n",
    "# 1 if either condition is met, else 0\n",
    "df[\"final_target\"] = (df[\"target_lp_sh_6\"]).astype(int)\n",
    "\n",
    "skewness = df[\"lastPrice\"].skew()\n",
    "kurtosis = df[\"lastPrice\"].kurtosis()\n",
    "min_price = df[\"lastPrice\"].min()\n",
    "max_price = df[\"lastPrice\"].max()\n",
    "price_difference = max_price - min_price\n",
    "percentage_difference_from_min = (price_difference / min_price) * 100\n",
    "\n",
    "print(f\"Skewness of lastPrice: {skewness}\")\n",
    "print(f\"Kurtosis of lastPrice: {kurtosis}\")\n",
    "print(f\"Minimum of lastPrice: {min_price}\")\n",
    "print(f\"Maximum of lastPrice: {max_price}\")\n",
    "print(f\"Percentage Difference from Minimum: {percentage_difference_from_min}%\")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd325b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"future_return_pcnt_6\"].plot(figsize=(17, 5), title=\"future_return_pcnt_6 over time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"future_return_pcnt_6\")\n",
    "plt.grid(True)\n",
    "plt.axhline(y=5, color='r', linestyle='--', label='Threshold 5%')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df[\"final_target\"].plot(figsize=(17, 3), title=\"final_target over time\")\n",
    "#df[\"future_return_pcnt_3\"].plot(figsize=(17, 3), title=\"final_target over time3\")\n",
    "#df[\"future_return_pcnt_6\"].plot(figsize=(17, 3), title=\"final_target over time6\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"final_target\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67281c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_loader = df[[\"price_change\", \"volume_change\", \"bid_ask_ratio\", \"mean_price_2\", \"mean_price_4\", \"final_target\"]]\n",
    "X = df_for_loader.drop(columns=[\"final_target\"])\n",
    "y = df_for_loader[\"final_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from db.dataset import TimeSeriesDataset, create_sequences\n",
    "\n",
    "TEST_SIZE = 0.2  # 20% для тестовой выборки\n",
    "RANDOM_SEED = 42\n",
    "VALIDATION_SPLIT_RATIO = 0.15\n",
    "SEQUENCE_LENGTH = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 1. Разделение исходных данных на обучающую и тестовую выборки (хронологически)\n",
    "# Используем меньший test_size для сохранения большего количества данных для обучения/валидации\n",
    "X_train_val_df, X_test_df, y_train_val_series, y_test_series = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Train/Validation X_df shape: {X_train_val_df.shape}, y_series shape: {y_train_val_series.shape}\")\n",
    "print(f\"Test X_df shape: {X_test_df.shape}, y_series shape: {y_test_series.shape}\")\n",
    "\n",
    "# 2. Разделение Train+Validation на Train и Validation (хронологически!)\n",
    "# Валидационная выборка - это последние X% от train_val_series\n",
    "val_size = int(len(X_train_val_df) * VALIDATION_SPLIT_RATIO)\n",
    "# Убедимся, что val_size хотя бы 1, чтобы избежать пустых выборок\n",
    "val_size = max(1, val_size)\n",
    "\n",
    "X_train_df = X_train_val_df.iloc[:-val_size]\n",
    "y_train_series = y_train_val_series.iloc[:-val_size]\n",
    "X_val_df = X_train_val_df.iloc[-val_size:]\n",
    "y_val_series = y_train_val_series.iloc[-val_size:]\n",
    "\n",
    "print(f\"\\nTrain X_df shape: {X_train_df.shape}, y_series shape: {y_train_series.shape}\")\n",
    "print(f\"Validation X_df shape: {X_val_df.shape}, y_series shape: {y_val_series.shape}\")\n",
    "\n",
    "# Очень важно: Проверить количество единиц в val и test наборах!\n",
    "print(f\"Classes in y_train_series:\\n{y_train_series.value_counts()}\")\n",
    "print(f\"Classes in y_val_series:\\n{y_val_series.value_counts()}\")\n",
    "print(f\"Classes in y_test_series:\\n{y_test_series.value_counts()}\")\n",
    "\n",
    "\n",
    "# 3. Создание временных последовательностей\n",
    "X_train_sequences, y_train_sequences = create_sequences(X_train_df, y_train_series, SEQUENCE_LENGTH)\n",
    "X_val_sequences, y_val_sequences = create_sequences(X_val_df, y_val_series, SEQUENCE_LENGTH)\n",
    "X_test_sequences, y_test_sequences = create_sequences(X_test_df, y_test_series, SEQUENCE_LENGTH)\n",
    "\n",
    "print(f\"\\nShapes of generated sequences:\")\n",
    "print(f\"X_train_sequences: {X_train_sequences.shape}, y_train_sequences: {y_train_sequences.shape}\")\n",
    "print(f\"X_val_sequences: {X_val_sequences.shape}, y_val_sequences: {y_val_sequences.shape}\")\n",
    "print(f\"X_test_sequences: {X_test_sequences.shape}, y_test_sequences: {y_test_sequences.shape}\")\n",
    "\n",
    "# 4. Преобразование в PyTorch тензоры\n",
    "X_train_tensor = torch.tensor(X_train_sequences, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_sequences, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_sequences, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_sequences, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_sequences, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_sequences, dtype=torch.float32)\n",
    "\n",
    "# 5. Создание DataLoader'ов\n",
    "train_dataset = TimeSeriesDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TimeSeriesDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_dataset = TimeSeriesDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f065c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
